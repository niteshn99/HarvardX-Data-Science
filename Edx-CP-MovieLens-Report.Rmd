---
title: "Report - MovieLens Recommender System Capstone Project"
author: "Nitesh Kumar Gupta - Harvard Data Science Professional"
date: "11/17/2020"
output: 
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
    highlight: pygments
    keep_tex: true
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center', cache=FALSE, cache.lazy = FALSE)
```


```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Install all needed libraries if it is not present
if(!require(tidyverse)) install.packages("tidyverse") 
if(!require(kableExtra)) install.packages("kableExtra")
if(!require(tidyr)) install.packages("tidyr")
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(stringr)) install.packages("stringr")
if(!require(forcats)) install.packages("forcats")
if(!require(ggplot2)) install.packages("ggplot2")
```

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Loading all needed libraries
library(dplyr)
library(tidyverse)
library(kableExtra)
library(tidyr)
library(stringr)
library(forcats)
library(ggplot2)
```

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 3.6 or earlier:
# movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
#                                            title = as.character(title),
#                                            genres = as.character(genres))
# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

\newpage

# Executive Summary

The purpose for this project is to create a movie recommender system using MovieLens dataset provided as bootstrap code to load data. 

The version of movielens dataset received after execution of bootstrap code provided within requirement contains approximately 10 Milions of movies ratings which is divided in approximately 9 Million records for training and 1 Million records for validation. Looking at dataset it can be concluded that it is a small subset of a much larger and famous dataset with several millions of ratings. Into the training dataset there are approximately **70,000 users** and **11,000 different movies** divided in 20 genres such as Sci-Fi, Romance, Action, Adventure, Horror, Drama, Thriller and more.

As per requirement, the recommender systems built on this dataset has been evaluated and chosen based on the RMSE - Root Mean Squared Error value. A model with RMSE value lower than **0.87750** is concluded model as a good fit for purpose. The mathematical expression used to calculate RMSE is as per below: 

$$\mbox{RMSE} = \sqrt{\frac{1}{n}\sum_{t=1}^{n}e_t^2}$$
Below is a programmatic representation of above expression in a form of R programming Function which has been used across this project to calculate RMSE value for different models.

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# The RMSE function that will be used in this project is:
RMSE <- function(true_ratings = NULL, predicted_ratings = NULL) {
    sqrt(mean((true_ratings - predicted_ratings)^2))
}
```   

Based on the outcomes of exploratory data analysis and different model evaluation, the **Regularized Movie + User + Genre Model** is capable to reach a RMSE of **0.8627121**, which is really good.

# Exploratory Data Analysis

## Inital data Exploration

The 10 Million records are divided into two dataset namely ```edx``` for model training purpose and ```validation``` for the model validation phase. 

The ```edx``` training dataset contains approximately 9 Million of rows having approximately 70,000 distinct users and 11,000 distinct movies with rating score between 0.5 and 5. There is no missing values (0 or NA).

**edx dataset**

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>% summarize(Users = n_distinct(userId),
              Movies = n_distinct(movieId)) %>% 
kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                 position = "center",
                 font_size = 10,
                 full_width = FALSE)
```

**Missing Values in both dataset**
```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
sapply(edx, function(x) sum(is.na(x))) %>% 
kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                 position = "center",
                 font_size = 10,
                 full_width = FALSE)
```

The MovieLens dataset have six features/variables/columns in both edx and validation datasets:

- **userId** ```<integer>``` that contains the unique identification number for each user.
- **movieId** ```<numeric>``` that contains the unique identification number for each movie.
- **rating** ```<numeric>``` that contains the rating of one movie by one user. Ratings are made on a 5-Star scale with half-star increments.
- **timestamp** ```<integer>``` that contains the timestamp for one specific rating provided by one user.
- **title** ```<character>``` that contains the title of each movie including the year of the release.
- **genres** ```<character>``` that contains a list of pipe-separated of genre of each movie.


**First 6 Rows of edx dataset**

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
head(edx) %>%
   kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                 position = "center",
                 font_size = 10,
                 full_width = FALSE)
```
\newpage

## Dataset Pre-Processing and Feature Engineering

Looking at first six sample rows of training dataset, we can clearly notice that the ```genres``` is a list values in string format separated by pipe symbol. It's necessary to extract them in rows for more consistent, robust and precise estimate. We also observe that the ```title``` contains the year when the movie was released. Movie released year may be necessary factor to predict the movie rating. Finally, extracting the year and the month for each rating from ```timestamp``` may be beneficial as they might have correlation with movie rating.

The pre-processing phase and feature engineering is composed by four steps as mentioned below:

1. Convert ```timestamp``` to a human readable date format.
2. Extract the month and the year from the date.
3. Extract the movie release year for each movie from the title. Clean title by removing release year.
4. Separate each genre from the pipe-separated value. It increases the size of both datasets as separate rows will get created for each genre.

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# Convert timestamp to a human readable date format in both traning and validation dataset

edx$formated_timestamp <- as.POSIXct(edx$timestamp, origin="1970-01-01")
validation$formated_timestamp <- as.POSIXct(validation$timestamp, origin="1970-01-01")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# Extract the year and month of rating in both dataset

edx$yearOfRating <- format(edx$formated_timestamp,"%Y")
edx$monthOfRating <- format(edx$formated_timestamp,"%m")

validation$yearOfRating <- format(validation$formated_timestamp,"%Y")
validation$monthOfRating <- format(validation$formated_timestamp,"%m")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# Extract the year of release for each movie in both dataset
# edx dataset

edx <- edx %>%
  mutate(title = str_trim(title)) %>%
  extract(title, c("titleTemp", "release"), regex = "^(.*) \\(([0-9 \\-]*)\\)$", remove = F) %>%
  mutate(release = if_else(str_length(release) > 4, as.integer(str_split(release, "-", simplify = T)[1]), as.integer(release))) %>%
  mutate(title = if_else(is.na(titleTemp), title, titleTemp)) %>%
  select(-titleTemp)


# validation dataset

validation <- validation %>%
  mutate(title = str_trim(title)) %>%
  extract(title, c("titleTemp", "release"), regex = "^(.*) \\(([0-9 \\-]*)\\)$", remove = F) %>%
  mutate(release = if_else(str_length(release) > 4, as.integer(str_split(release, "-", simplify = T)[1]), as.integer(release))) %>%
  mutate(title = if_else(is.na(titleTemp), title, titleTemp)) %>%
  select(-titleTemp)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# Extract the genre in edx datasets and label missing genre in case any to include them in summary
# Error in separate_rows(genre, sep = "\\|") : object 'genre' not found, thus need to first convert it into character

edx <- edx %>%
  mutate(genre = fct_explicit_na(genres, na_level = "(missing)")) %>%
  mutate(genre = as.character(genre)) %>%
  separate_rows(genre, sep = "\\|")


# Extract the genre in validation datasets

validation <- validation %>%
  mutate(genre = fct_explicit_na(genres, na_level = "(missing)")) %>%
  mutate(genre = as.character(genre)) %>%
  separate_rows(genre, sep = "\\|")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# remove unnecessary columns on both dataset

edx <- edx %>% select(userId, movieId, rating, title, genre, release, yearOfRating, monthOfRating)
validation <- validation %>% select(userId, movieId, rating, title, genre, release, yearOfRating, monthOfRating)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# Convert newly added features into numeric data type for calculation precision

edx$yearOfRating <- as.numeric(edx$yearOfRating)
edx$monthOfRating <- as.numeric(edx$monthOfRating)
edx$release <- as.numeric(edx$release)

validation$yearOfRating <- as.numeric(validation$yearOfRating)
validation$monthOfRating <- as.numeric(validation$monthOfRating)
validation$release <- as.numeric(validation$release)
```

After pre-processing and feature engineering, the data, ```edx``` dataset looks like this with additional 5 features and in total 11 features. Similarly, same 5 new features has been added to validation dataset:

**Pre-processed and feature engineered edx datadaset**
First six rows of edx training dataset.
```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# Output the processed training dataset
head(edx) %>%
   kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                 position = "center",
                 font_size = 10,
                 full_width = FALSE)
```

**Pre-processed and feature engineered validation datadaset**
First six rows of validation dataset.
```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# Output the processed validation dataset
head(validation) %>%
   kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                 position = "center",
                 font_size = 10,
                 full_width = FALSE)
```

\newpage

## Rating Distribution

**Overview of Rating Distribution**

Below graph depicts movie rating distribution on a scale of 0 to 5 star with an increment of 0.5 (half) star. It can be clearly seen that there is no zero star rating. In addition, whole number stars i.e. 1,2,3,4, and 5 are more common as compared to non-whole number stars such as 0.5,1.5,2.5,3.5, and 4.5.

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
hist(edx$rating, main="Distribution of User's Ratings", xlab="Rating")
```

**Overview of Rating Frequency through Months and Years**

Below bar graphs shows movie rating frequency distribution through year months and years. It can se clearly seen that November month has accounted for highest number of ratings followed by December where as least number of rating has been received during the month of September.
Year 2000 accounted for largest number of rating followed by 2005 where as 1998 recorded lowest number of ratings.

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
hist(edx$monthOfRating, main="Frequency of User's Ratings through Month", xlab="Month")
hist(edx$yearOfRating, main="Frequency of User's Ratings through Years", xlab="Years")
```

### Numbers of Ratings per Movie

Below histogram graph shows numbers of rating per movie between year 1996 and 2008. After looking at graph it can be clearly seen that movie ids between 1000 and 2500 has not been rated at all. In addition, majority of rating has been received for movies with IDs between 1 and 1000. Very few ratings has been recorded for movies having movieIds greater than 2500. Overall, it can be concluded that most popular movies are those which have lowest movieIds.

```{r echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
ggplot(edx, aes(movieId)) +
theme_classic()  +
geom_histogram(bins=500) +
labs(title = "Ratings Frequency Distribution Per Title (MovieID)",
    x = "Title (MovieID)",
    y = "Frequency")
```

### Top Rated Movies

Below bar graph shows top 25 movies with total number of ratings received. It can be clearly seen that Forrest Gump has received highest number of rating where as movies like Babe, The Mask, and Batman Forever stood at the end of top 25 movie list. 

```{r echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>%
   group_by(title) %>%
   summarise(count = n()) %>%
   arrange(desc(count)) %>%
   head(n=25) %>%
   ggplot(aes(title, count)) +
   theme_classic()  +
   geom_col() +
   theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 7)) +
   labs(title = "Ratings Frequency Distribution Per Title - TOP 25 Movies",
        x = "Title",
        y = "Frequency")
```

```{r echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>%
   group_by(title) %>%
   summarise(count = n()) %>%
   arrange(desc(count)) %>%
   head(n=25) %>%
   kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                 position = "center",
                 font_size = 10,
                 full_width = FALSE)
```

### Mean Distribution per Title (Movie ID)

Below histogram and table shows rating mean distribution per movie title. It can be clearly seen that there are few movies such as The Blue Light, Sun Alley, and few more which has recorded 5 star rating. However, 3 star rating appears to be recorded for highest number. 0.5 (half) star and 5 star has been given to very few movies.

```{r echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>%
   group_by(title) %>%
   summarise(mean = mean(rating)) %>%
   ggplot(aes(mean)) +
   theme_classic()  +
   geom_histogram(bins=12) +
   labs(title = "Mean Distribution per Title",
        x = "Mean",
        y = "Frequency")
```

```{r echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>%
   group_by(title) %>%
   summarise(mean = mean(rating)) %>%
   arrange(desc(mean)) %>%
   head(n=25) %>%
   kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                 position = "center",
                 font_size = 10,
                 full_width = FALSE)
```

### Median Distribution per Title (Movie ID)

Below graph and table shows median distribution per movie title. Similar to our previous findings, very few movies like The Blue Light, Sun Alley, and few more has got highest median value of 5. Majority of movies, above frequency 3000, has received 3 star rating.  4 and 4.5 star remains second popular rating.

```{r echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>%
   group_by(title) %>%
   summarise(median = median(rating)) %>%
   ggplot(aes(median)) +
   theme_classic()  +
   geom_histogram(bins=12) +
   labs(title = "Median Distribution per Title",
        x = "Median",
        y = "Frequency")
```

```{r echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>%
   group_by(title) %>%
   summarise(median = median(rating)) %>%
   arrange(desc(median)) %>%
   head(n=25) %>%
   kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                 position = "center",
                 font_size = 10,
                 full_width = FALSE)
```

\newpage

## Genre Analysis

### Rating Distribution per Genre

**Overview of Rating distribution over Genre**

Below bar graph shows rating distribution over genre. Genre Drama and Comedy seems to be remain most and second most popular in terms of rating where as least rating has been recorded for genre type IMAX. Documentary remains second last in terms of receiving ratings. Another thing to be noted here is that 7 movies does not have genre.

```{r echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>%
   group_by(genre) %>%
   summarise(count = n()) %>%
   ggplot(aes(genre, count)) +
   theme_classic()  +
   geom_col() +
   theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
   labs(title = "Ratings Frequency Distribution Per Genre",
        x = "Genre",
        y = "Frequency")
```

```{r echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>%
   group_by(genre) %>%
   summarise(count = n()) %>%
   arrange(desc(count)) %>%
   kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                 position = "center",
                 font_size = 10,
                 full_width = FALSE)
```

### Mean Distribution per Genre

Below bar graph shows rating mean distribution per genre and it can be clearly seen that mean remains consistent around 3.5 with slight variance.

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>%
   group_by(genre) %>%
   summarise(mean = mean(rating)) %>%
   ggplot(aes(genre, mean)) +
   theme_classic()  +
   geom_col() +
   theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
   labs(title = "Mean Distribution per Genre",
        x = "Genre",
        y = "Mean")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>%
   group_by(genre) %>%
   summarise(mean = mean(rating)) %>%
   arrange(desc(mean)) %>%
   head(n=35) %>%
   kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                 position = "center",
                 font_size = 10,
                 full_width = FALSE)
```

### Median Distribution per Genre

Below bar graph shows rating median distribution per genre. Similar to mean, median remain consistance between 4 and 3.5 star rating.

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>%
   group_by(genre) %>%
   summarise(median = median(rating)) %>%
   ggplot(aes(genre, median)) +
   theme_classic()  +
   geom_col() +
   theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
   labs(title = "Median Distribution per Genre",
        x = "Genre",
        y = "Median")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
edx %>%
   group_by(genre) %>%
   summarise(median = median(rating)) %>%
   arrange(desc(median)) %>%
   head(n=35) %>%
   kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                 position = "center",
                 font_size = 10,
                 full_width = FALSE)
```

\newpage

# Analysis - Model Building and Evaluation

## Naive Baseline Model

The simplest model that someone can build, is a Naive Model which ALWAYS predict the mean value. In this case, the mean is approximately equal to 3.5.

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
paste("The mean is:", as.character(mean(edx$rating)))
```

### Naive Mean-Baseline Model

The formula used is:

$$Y_{u,i} = \hat{\mu} + \varepsilon_{u,i}$$

With $\hat{\mu}$ is the mean and $\varepsilon_{i,u}$ is the independent errors sampled from the same distribution centered at 0.

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# Average by all movies rating
mu_hat <- mean(edx$rating)

# RMSE on the validation set
mean_model_rmse <- RMSE(validation$rating, mu_hat) #1.052 root mean square error

# Since we are going to explore other various methods/models, 
# I need a variable to cache RMSE result of each for future reference.
results <- data.frame(model="Naive Mean - Baseline Model", RMSE=mean_model_rmse)
```

The RMSE on the ```validation``` dataset is **1.052**. It is very far from the target RMSE (below 0.87) which indicates poor performance for the model.

## Movie-Based Model, a Content-based Approach

Taking content into account is first approach towards Non-Naive model. In this case, considering co-relation between higher and lower movie rating will result in better performance than Naive model.

The formula used is:

$$Y_{u,i} = \hat{\mu} + b_m + \epsilon_{u,i}$$

With $\hat{\mu}$ is the mean and $\varepsilon_{i,u}$ is the independent errors sampled from the same distribution centered at 0. The $b_m$ is a measure for the popularity of movie $m$, i.e. the bias of movie $m$.

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# Average by movie
movie_avgs <- edx %>%
  group_by(movieId) %>%
  summarize(b_m = mean(rating - mu_hat))

# Predicted ratings on validation dataset
movie_model_pred <- validation %>%
  left_join(movie_avgs, by='movieId') %>%
  mutate(pred = mu_hat + b_m) %>%
  pull(pred)

movie_model_rmse<- RMSE(validation$rating, movie_model_pred) # 0.941 RMSE


# Adding movie model to the results
results <- results %>% add_row(model="Movie - Based Model", RMSE=movie_model_rmse)
```

The RMSE on the ```validation``` dataset is **0.941**. It better than the Naive Mean-Baseline Model, but it is also very far from the target RMSE (below 0.87) which indicates poor performance model considering expectation of below 0.87 RMSE.

## Movie + User Model, a User-based approach

The second Non-Naive Model consider that the users have different tastes and rate differently.

The formula used is:

$$Y_{u,i} = \hat{\mu} + b_m + b_u + \epsilon_{u,i}$$

With $\hat{\mu}$ is the mean and $\varepsilon_{i,u}$ is the independent errors sampled from the same distribution centered at 0. The $b_m$ is a measure for the popularity of movie $m$, i.e. the bias of movie $m$. The  $b_u$ is a measure for the mildness of user $u$, i.e. the bias of user $u$.

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# Average by user
user_avgs <- edx %>%
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu_hat - b_m))

# Predicted ratings on validation dataset using movie and user average
movie_user_pred <- validation %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu_hat + b_m + b_u) %>%
  pull(pred)

movie_user_model_rmse <- RMSE(validation$rating, movie_user_pred)

# Adding movie user model to the results
results <- results %>% add_row(model="Movie + User Based Model", RMSE=movie_user_model_rmse)
```

The RMSE on the ```validation``` dataset is **0.8633** and very close to expected RMSE of 0.87. The Movie + User Based Model reaches the desired performance; however, regularization techniques may improve the performance with little margin. We will see result of regularization techniques in later paragraphs.

## Movie + User + Genre Model, the Genre Popularity

The formula used is:

$$Y_{u,i} = \hat{\mu} + b_m + b_u + b_{u,g} + \epsilon_{u,i}$$

With $\hat{\mu}$ is the mean and $\varepsilon_{i,u}$ is the independent errors sampled from the same distribution centered at 0. The $b_m$ is a measure for the popularity of movie $m$, i.e. the bias of movie $m$. The  $b_u$ is a measure for the mildness of user $u$, i.e. the bias of user $u$. The  $b_{u,g}$ is a measure for how much a user $u$ likes the genre $g$.

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# Average by genre
genre_avgs <- edx %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  group_by(genre) %>%
  summarize(b_u_g = mean(rating - mu_hat - b_m - b_u))

# Predicted ratings on validation dataset using movie, user, and genre
movie_user_genre_pred <- validation %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  left_join(genre_avgs, by='genre') %>%
  mutate(pred = mu_hat + b_m + b_u + b_u_g) %>%
  pull(pred)

movie_user_genre_model_rmse <- RMSE(validation$rating, movie_user_genre_pred) # 0.863 RMSE

# Adding movie user genre model to the results
results <- results %>% add_row(model="Movie + User + Genre Based Model", RMSE=movie_user_genre_model_rmse)
```

The RMSE on the ```validation``` dataset is **0.8632** and this is very good result slightly better than Movie + User based model.  The Movie + User + Genre Based Model reaches the desired performance but adding the ```genre``` predictor, doesn't improve significantly the model's performance. Applying the regularization techniques, can improve the performance just a little which we are going to explore in next section.

\newpage

## Regularization

The regularization method allows us to add a penalty $\lambda$ (lambda) to penalizes movies with large estimates from a small sample size. In order to optimize b_m, we can use below equation:

$$\frac{1}{N} \sum_{u,i} (y_{u,i} - \mu - b_{i})^{2} + \lambda \sum_{i} b_{i}^2$$


which can be further reduced to this equation:   

$$\hat{b_{i}} (\lambda) = \frac{1}{\lambda + n_{i}} \sum_{u=1}^{n_{i}} (Y_{u,i} - \hat{\mu}) $$  


### Regularized Movie-Based Model

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# Regularization to penalize movies with large estimates from small sample size.
# Penalty table 
penalties <- seq(0, 10, 0.1)

# Predicted ratings on validation dataset using different values of penalties based on movie
rmses <- sapply(penalties, function(penalty) {
  
  # Average by movie
  b_m <- edx %>%
    group_by(movieId) %>%
    summarize(b_m = sum(rating - mu_hat) / (n() + penalty))
  
  # Compute the predicted ratings on validation dataset
  predicted_ratings <- validation %>%
    left_join(b_m, by='movieId') %>%
    mutate(pred = mu_hat + b_m) %>%
    pull(pred)
  
  # Predict the RMSE on the validation set
  return(RMSE(validation$rating, predicted_ratings))
})

# plot the result of penalties
df <- data.frame(RMSE = rmses, penalties = penalties)
ggplot(df, aes(penalties, rmses)) +
   theme_classic()  +
   geom_point() +
   labs(title = "RMSEs vs penalties - Regularized Movie Based Model",
        y = "RMSEs",
        x = "penalties")

# Get the penalty value that minimize the RMSE
min_penalty <- penalties[which.min(rmses)] # 3.6

# Predict the RMSE on the validation set
regularized_movie_model_rmse <- min(rmses) # 0.941 RMSE

# Adding the regularized movie model rmse to the results
results <- results %>% add_row(model="Regularized Movie - Based Model", RMSE=regularized_movie_model_rmse)
```

The RMSE on the ```validation``` dataset is **0.9410** and this is very far from desired RMSE of **0.87**. The Regularized Movie + User Based Model does not reaches the desired performance.

### Regularized Movie + User Model

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# Predicted ratings on validation dataset using different values of penalties based on movie and user

rmses <- sapply(penalties, function(penalty) {
  
  # Average by movie
  b_m <- edx %>%
    group_by(movieId) %>%
    summarize(b_m = sum(rating - mu_hat) / (n() + penalty))
  
  # Average by user and movie
  b_u <- edx %>%
    left_join(b_m, by='movieId') %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_m - mu_hat) / (n() + penalty))
  
  # Predicted ratings on validation dataset by movie and user
  predicted_ratings <- validation %>%
    left_join(b_m, by='movieId') %>%
    left_join(b_u, by='userId') %>%
    mutate(pred = mu_hat + b_m + b_u) %>%
    pull(pred)
  
  # Predict the RMSE on the validation set
  return(RMSE(validation$rating, predicted_ratings))
})

# plot the result of penaltys
df <- data.frame(RMSE = rmses, penalties = penalties)
ggplot(df, aes(penalties, rmses)) +
   theme_classic()  +
   geom_point() +
   labs(title = "RMSEs vs penalties - Regularized Movie + User Model",
        y = "RMSEs",
        x = "penalties")

# Get the penalty value that minimize the RMSE
min_penalty <- penalties[which.min(rmses)] # 10

# Predict the RMSE on the validation set
regularized_movie_user_model_rmse <- min(rmses) # 0.8628

# Adding the results to the results dataset
results <- results %>% add_row(model="Regularized Movie + User Based Model", RMSE=regularized_movie_user_model_rmse)
```

The RMSE on the ```validation``` dataset is **0.8628** and reaches the desired RMSE value. However, Regularized Movie + User Based Model improves by just a little as compared to the result of the Non-Regularized Movie + User Model which is **0.8633**.

### Regularized Movie + User + Genre Model

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# Compute the predicted ratings on validation dataset using different values of penalties
rmses <- sapply(penalties, function(penalty) {
  
  # Average by movie
  b_m <- edx %>%
    group_by(movieId) %>%
    summarize(b_m = sum(rating - mu_hat) / (n() + penalty))
  
  # Average by user
  b_u <- edx %>%
    left_join(b_m, by='movieId') %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_m - mu_hat) / (n() + penalty))
  
  # Average by movie and user
  b_u_g <- edx %>%
    left_join(b_m, by='movieId') %>%
    left_join(b_u, by='userId') %>%
    group_by(genre) %>%
    summarize(b_u_g = sum(rating - b_m - mu_hat - b_u) / (n() + penalty))
  
  # Compute the predicted ratings on validation dataset using movie, user, and genre
  predicted_ratings <- validation %>%
    left_join(b_m, by='movieId') %>%
    left_join(b_u, by='userId') %>%
    left_join(b_u_g, by='genre') %>%
    mutate(pred = mu_hat + b_m + b_u + b_u_g) %>%
    pull(pred)
  
  # Predict the RMSE on the validation set
  return(RMSE(validation$rating, predicted_ratings))
})

# plot the result of penalties
df <- data.frame(RMSE = rmses, penalties = penalties)
ggplot(df, aes(penalties, rmses)) +
   theme_classic()  +
   geom_point() +
   labs(title = "RMSEs vs penalties - Regularized Movie + User + Genre Model",
        y = "RMSEs",
        x = "penalties")

# Get the penalties value that minimize the RMSE
min_penalty <- penalties[which.min(rmses)] # 14.8

# Predict the RMSE on the validation set
regularized_movie_user_genre_model_rmse <- min(rmses) # 0.8626 (no improvement observed on higher penalities)

# Adding the regularized movie user genre RMSE to the results
results <- results %>% add_row(model="Regularized Movie + User + Genre Based Model", RMSE=regularized_movie_user_genre_model_rmse)
```

The RMSE on the ```validation``` dataset is **0.8627** which is the best result among all models we have created so far. Although the Regularized Movie + User + Genre Based Model improves RMSE score by just a little as compared to the result of the Non-Regularized Movie + User + Genre Based Model RMSE score of **0.8632**, it performs better than all other models.

# Results

Below table list all models built during this project using training ```edx``` dataset and validated on the ```validation``` dataset.

```{r echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# Shows the results
results %>% 
   kable() %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
             position = "center",
             font_size = 10,
             full_width = FALSE)
```

# Conclusion

Overall, ```movieId``` and ```userId``` contributes more than the ```genre``` predictor. Although desired performance can be achieved without applying regularization techniques, consider applying regularization technique will be a good idea as it improves overall performance and reaches best RMSE score of **0.8627** which is best among all other trained models.

\newpage

# Appendix

## 1a - Initial Code privided by edX and code for MovieLens training and validation dataset prepration

```
##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 3.6 or earlier:
# movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
#                                            title = as.character(title),
#                                            genres = as.character(genres))
# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```
## 1b - Code for MovieLens data analysis
```
#######################################################
# MovieLens feature engineering and data analysis
#######################################################

# Install all needed libraries if it is not present
if(!require(tidyverse)) install.packages("tidyverse") 
if(!require(kableExtra)) install.packages("kableExtra")
if(!require(tidyr)) install.packages("tidyr")
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(stringr)) install.packages("stringr")
if(!require(forcats)) install.packages("forcats")
if(!require(ggplot2)) install.packages("ggplot2")

# Loading all needed libraries
library(dplyr)
library(tidyverse)
library(kableExtra)
library(tidyr)
library(stringr)
library(forcats)
library(ggplot2)

# The general RMSE function that will be used to evaluate overall performance of models:
RMSE <- function(true_ratings = NULL, predicted_ratings = NULL) {
  sqrt(mean((true_ratings - predicted_ratings)^2))
}

# MovieLens data preparation work including feature engineering and data type correction
# Convert timestamp to a human readable date format in both traning and validation dataset
edx$formated_timestamp <- as.POSIXct(edx$timestamp, origin="1970-01-01")
validation$formated_timestamp <- as.POSIXct(validation$timestamp, origin="1970-01-01")


# Extract the year and month of rating in both dataset
edx$yearOfRating <- format(edx$formated_timestamp,"%Y")
edx$monthOfRating <- format(edx$formated_timestamp,"%m")
validation$yearOfRating <- format(validation$formated_timestamp,"%Y")
validation$monthOfRating <- format(validation$formated_timestamp,"%m")

# Extract the year of release for each movie in both dataset
# edx dataset
edx <- edx %>%
  mutate(title = str_trim(title)) %>%
  extract(title, c("titleTemp", "release"), regex = "^(.*) \\(([0-9 \\-]*)\\)$", remove = F) %>%
  mutate(release = if_else(str_length(release) > 4, as.integer(str_split(release, "-", simplify = T)[1]), as.integer(release))) %>%
  mutate(title = if_else(is.na(titleTemp), title, titleTemp)) %>%
  select(-titleTemp)


# validation dataset
validation <- validation %>%
  mutate(title = str_trim(title)) %>%
  extract(title, c("titleTemp", "release"), regex = "^(.*) \\(([0-9 \\-]*)\\)$", remove = F) %>%
  mutate(release = if_else(str_length(release) > 4, as.integer(str_split(release, "-", simplify = T)[1]), as.integer(release))) %>%
  mutate(title = if_else(is.na(titleTemp), title, titleTemp)) %>%
  select(-titleTemp)


# Extract the genre in edx datasets and label missing genre in case any to include them in summary
# Error in separate_rows(genre, sep = "\\|") : object 'genre' not found, thus need to first convert it into character
edx <- edx %>%
  mutate(genre = fct_explicit_na(genres, na_level = "(missing)")) %>%
  mutate(genre = as.character(genre)) %>%
  separate_rows(genre, sep = "\\|")


# Extract the genre in validation datasets
validation <- validation %>%
  mutate(genre = fct_explicit_na(genres, na_level = "(missing)")) %>%
  mutate(genre = as.character(genre)) %>%
  separate_rows(genre, sep = "\\|")


# remove unnecessary columns on both dataset
edx <- edx %>% select(userId, movieId, rating, title, genre, release, yearOfRating, monthOfRating)
validation <- validation %>% select(userId, movieId, rating, title, genre, release, yearOfRating, monthOfRating)


# Convert newly added features into numeric data type for calculation precision
edx$yearOfRating <- as.numeric(edx$yearOfRating)
edx$monthOfRating <- as.numeric(edx$monthOfRating)
edx$release <- as.numeric(edx$release)
validation$yearOfRating <- as.numeric(validation$yearOfRating)
validation$monthOfRating <- as.numeric(validation$monthOfRating)
validation$release <- as.numeric(validation$release)


# Models exploration

# Average by all movies rating
mu_hat <- mean(edx$rating)

# RMSE on the validation set
mean_model_rmse <- RMSE(validation$rating, mu_hat) #1.052 root mean square error

# Since we are going to explore other various methods/models, 
# I need a variable to cache RMSE result of each for future reference.
results <- data.frame(model="Naive Mean - Baseline Model", RMSE=mean_model_rmse)

# Average by movie
movie_avgs <- edx %>%
  group_by(movieId) %>%
  summarize(b_m = mean(rating - mu_hat))

# Predicted ratings on validation dataset
movie_model_pred <- validation %>%
  left_join(movie_avgs, by='movieId') %>%
  mutate(pred = mu_hat + b_m) %>%
  pull(pred)

movie_model_rmse<- RMSE(validation$rating, movie_model_pred) # 0.941 RMSE

# Adding movie model to the results
results <- results %>% add_row(model="Movie - Based Model", RMSE=movie_model_rmse)

# Average by user
user_avgs <- edx %>%
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu_hat - b_m))

# Predicted ratings on validation dataset using movie and user average
movie_user_pred <- validation %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu_hat + b_m + b_u) %>%
  pull(pred)

movie_user_model_rmse <- RMSE(validation$rating, movie_user_pred)

# Adding movie user model to the results
results <- results %>% add_row(model="Movie + User Based Model", RMSE=movie_user_model_rmse)

# Average by genre
genre_avgs <- edx %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  group_by(genre) %>%
  summarize(b_u_g = mean(rating - mu_hat - b_m - b_u))

# Predicted ratings on validation dataset using movie, user, and genre
movie_user_genre_pred <- validation %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  left_join(genre_avgs, by='genre') %>%
  mutate(pred = mu_hat + b_m + b_u + b_u_g) %>%
  pull(pred)

movie_user_genre_model_rmse <- RMSE(validation$rating, movie_user_genre_pred) # 0.863 RMSE

# Adding movie user genre model to the results
results <- results %>% add_row(model="Movie + User + Genre Based Model", RMSE=movie_user_genre_model_rmse)

# Regularization to penalize movies with large estimates from small sample size.

# Penalty table 
penalties <- seq(0, 10, 0.1)


# Predicted ratings on validation dataset using different values of penalties based on movie
rmses <- sapply(penalties, function(penalty) {
  
  # Average by movie
  b_m <- edx %>%
    group_by(movieId) %>%
    summarize(b_m = sum(rating - mu_hat) / (n() + penalty))
  
  # Compute the predicted ratings on validation dataset
  predicted_ratings <- validation %>%
    left_join(b_m, by='movieId') %>%
    mutate(pred = mu_hat + b_m) %>%
    pull(pred)
  
  # Predict the RMSE on the validation set
  return(RMSE(validation$rating, predicted_ratings))
})


# Get the penalty value that minimize the RMSE
min_penalty <- penalties[which.min(rmses)] # 3.6

# Predict the RMSE on the validation set
regularized_movie_model_rmse <- min(rmses) # 0.941 RMSE

# Adding the regularized movie model rmse to the results
results <- results %>% add_row(model="Regularized Movie - Based Model", RMSE=regularized_movie_model_rmse)

# Predicted ratings on validation dataset using different values of penalties based on movie and user
rmses <- sapply(penalties, function(penalty) {
  
  # Average by movie
  b_m <- edx %>%
    group_by(movieId) %>%
    summarize(b_m = sum(rating - mu_hat) / (n() + penalty))
  
  # Average by user and movie
  b_u <- edx %>%
    left_join(b_m, by='movieId') %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_m - mu_hat) / (n() + penalty))
  
  # Predicted ratings on validation dataset by movie and user
  predicted_ratings <- validation %>%
    left_join(b_m, by='movieId') %>%
    left_join(b_u, by='userId') %>%
    mutate(pred = mu_hat + b_m + b_u) %>%
    pull(pred)
  
  # Predict the RMSE on the validation set
  return(RMSE(validation$rating, predicted_ratings))
})

# Get the penalty value that minimize the RMSE
min_penalty <- penalties[which.min(rmses)] # 10

# Predict the RMSE on the validation set
regularized_movie_user_model_rmse <- min(rmses) # 0.8628

# Adding the results to the results dataset
results <- results %>% add_row(model="Regularized Movie + User Based Model", RMSE=regularized_movie_user_model_rmse)


#################################################################################
# Testing above findings with higher penalties values for movie, user, and genre
#################################################################################

penalties <- seq(0, 15, 0.1)

# Compute the predicted ratings on validation dataset using different values of penalties
rmses <- sapply(penalties, function(penalty) {
  
  # Average by movie
  b_m <- edx %>%
    group_by(movieId) %>%
    summarize(b_m = sum(rating - mu_hat) / (n() + penalty))
  
  # Average by user
  b_u <- edx %>%
    left_join(b_m, by='movieId') %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_m - mu_hat) / (n() + penalty))
  
  # Average by movie and user
  b_u_g <- edx %>%
    left_join(b_m, by='movieId') %>%
    left_join(b_u, by='userId') %>%
    group_by(genre) %>%
    summarize(b_u_g = sum(rating - b_m - mu_hat - b_u) / (n() + penalty))
  
  # Compute the predicted ratings on validation dataset using movie, user, and genre
  predicted_ratings <- validation %>%
    left_join(b_m, by='movieId') %>%
    left_join(b_u, by='userId') %>%
    left_join(b_u_g, by='genre') %>%
    mutate(pred = mu_hat + b_m + b_u + b_u_g) %>%
    pull(pred)
  
  # Predict the RMSE on the validation set
  return(RMSE(validation$rating, predicted_ratings))
})

# Get the penalties value that minimize the RMSE
min_penalty <- penalties[which.min(rmses)] # 14.8

# Predict the RMSE on the validation set
regularized_movie_user_genre_model_rmse <- min(rmses) # 0.8626 (no improvement observed on higher penalities)

# Adding the regularized movie user genre RMSE to the results
results <- results %>% add_row(model="Regularized Movie + User + Genre Based Model", RMSE=regularized_movie_user_genre_model_rmse)

results
```

## 1c - Enviroment

```{r message=FALSE, warning=FALSE}
print("Operating System:")
version
```

```{r message=FALSE, warning=FALSE}
print("All installed packages")
installed.packages()
```